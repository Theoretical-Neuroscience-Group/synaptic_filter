{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jannes/Documents/Science/Real-Projects/P3-JP-Synapse-Paper/git-p3/learning_as_filtering_new\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_vs_input.png                 \u001b[34mnotebooks\u001b[m\u001b[m/\r\n",
      "MSE_vs_input_tauOU100_g0.png     \u001b[34mpkl_data\u001b[m\u001b[m/\r\n",
      "MSE_vs_input_tauOU100_gamma.png  pull.sh\r\n",
      "MSE_vs_input_tauOU100s.png       run_local.sh\r\n",
      "MSE_vs_input_tauOU400_gamma.png  run_remote.sh\r\n",
      "README.md                        \u001b[34msrc\u001b[m\u001b[m/\r\n",
      "main.py                          \u001b[34mutil\u001b[m\u001b[m/\r\n",
      "main.sh\r\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code new learning rule\n",
    "    - alpha_bar\n",
    "    - x_wiggle (low pass)\n",
    "- Ensure that gamma is constant\n",
    "- Think of systematic comparison of Sigma in 1d\n",
    "- Run on cluster for various hyperpars\n",
    "    - beta\n",
    "    - tau_x_wiggle\n",
    "    - tau_d\n",
    "    - check norm of x_eps\n",
    "    - (?)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "from src.plotting import *\n",
    "from src.update_functions import *\n",
    "from src.init_functions import *\n",
    "from src.run_functions import *\n",
    "\n",
    "def expspace(a0, an, n=50):\n",
    "    \"\"\" linspace in exp space \"\"\"\n",
    "    return (a0 * np.exp(np.log(an / a0) * np.linspace(0, 1, n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'t_num': 4000,\n",
    "     'dt': 0.001,\n",
    "     'dim':2,\n",
    "     'tau':0.025,\n",
    "     'g0':1,\n",
    "     'beta':0.5,\n",
    "     'mu_ou':0,\n",
    "     'sig2_ou':1,     \n",
    "     'tau_ou':1000, # s\n",
    "     'rule':'corr'\n",
    "    }\n",
    "p['g0dt'] = p['g0']*p['dt']\n",
    "\n",
    "# STDP\n",
    "p['delta_T'] = 0.01\n",
    "p['wait'] = 0.5 # s\n",
    "\n",
    "# correlation protocol\n",
    "p['correlated_times'] = np.array([0, 0.01]) # s, two spikes\n",
    "\n",
    "# bias\n",
    "p['include-bias'] = False\n",
    "p['sig2_oub'] = 1\n",
    "p['tau_oub'] = 0.025\n",
    "p['mu_oub'] = 1.0\n",
    "# spike response\n",
    "p['include-spike-response-kernel'] = True\n",
    "p['tau_alpha'] = 0.025\n",
    "p['amplitude_alpha'] = -3/p['beta']\n",
    "# single vector rules\n",
    "p['tau_z'] = 1\n",
    "\n",
    "p['tau_d'] = p['tau_ou'] # ?\n",
    "p['tau_x_wiggle'] = p['tau_ou'] # good\n",
    "p['compute_sig2'] = True\n",
    "p['gamma_equal_g0'] = True\n",
    "\n",
    "# performance sims:\n",
    "p['epoch_num'] = 10\n",
    "p['epoch_wait'] = 2\n",
    "p['rate'] = 40 # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check kernel how to make a kernel constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = {'x': np.zeros(10000)}\n",
    "dt = 0.001\n",
    "p['tau'] = 0.025\n",
    "eps0 = 1/p['tau']\n",
    "for k in range(10000-1):\n",
    "    Sx = int(k == 1000)\n",
    "    v['x'][k + 1] = (1 - dt / p['tau']) * v['x'][k] + Sx*eps0\n",
    "plt.plot(v['x'])\n",
    "plt.title(str(dt*sum(v['x'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance simulation for two values of the membrane time constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['tau_ou'] = 4\n",
    "p['tau_d'] = 1\n",
    "p['tau_x_wiggle'] = 1\n",
    "p['beta'] = 0.02\n",
    "p['dim'] = 1\n",
    "p['dt'] = 0.001\n",
    "\n",
    "p['include-spike-response-kernel'] = False\n",
    "p['include-bias'] = False\n",
    "\n",
    "p['tau'] = 0.025\n",
    "p['rule'] = 'exp-rm2'\n",
    "out,v = run_simulation(p,verbose=True,online=False)\n",
    "\n",
    "p['tau'] = 1\n",
    "p['rule'] = 'exp-rm2'\n",
    "out,v2 = run_simulation(p,verbose=True,online=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(v['x'], alpha=0.4)\n",
    "print(np.mean(v['x'])/p['rate'])\n",
    "plt.plot(v2['x'], alpha=0.4)\n",
    "print(np.mean(v2['x'])/p['rate'])\n",
    "plt.title('Overall activation only driven by rate, not tau_m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vplt(v,p,key='sig2',dim=0,cut=1,c=None,err=True,alpha=0.8)\n",
    "vplt(v2,p,key='sig2',dim=0,cut=1,c=None,err=True,alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance simulation for two learning rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['tau_ou'] = 4\n",
    "p['tau_d'] = 1\n",
    "p['tau_x_wiggle'] = 1\n",
    "p['beta'] = 0.02\n",
    "p['dim'] = 1\n",
    "p['dt'] = 0.001\n",
    "\n",
    "p['include-spike-response-kernel'] = False\n",
    "p['include-bias'] = False\n",
    "\n",
    "p['tau'] = 0.5\n",
    "p['rule'] = 'corr'\n",
    "out,v = run_simulation(p,verbose=True,online=False)\n",
    "\n",
    "p['rule'] = 'exp-rm2'\n",
    "out,v2 = run_simulation(p,verbose=True,online=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vplt(v,p,key='sig2',dim=0,cut=1,c=None,err=True,alpha=0.8)\n",
    "vplt(v2,p,key='sig2',dim=0,cut=1,c=None,err=True,alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance sims for multiple time constants on a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['tau_ou'] = 4\n",
    "tau_ds = [0.1,0.5,1]\n",
    "tau_x_wiggles = [1,1.5,2]\n",
    "f, axs = plt.subplots(3,3,sharex=True,sharey=True,figsize=[10,10])\n",
    "for ax, (tau_d, tau_x_wiggle) in zip(\n",
    "    axs.reshape(-1), it.product(tau_ds, tau_x_wiggles)):\n",
    "\n",
    "    p['tau_d'] = tau_d*p['tau_ou']\n",
    "    p['tau_x_wiggle'] = tau_x_wiggle*p['tau_ou']\n",
    "    p['beta'] = 0.02\n",
    "    p['dim'] = 1\n",
    "    p['dt'] = 0.001\n",
    "\n",
    "    p['include-spike-response-kernel'] = False\n",
    "    p['include-bias'] = False\n",
    "\n",
    "    p['rule'] = 'exp-rm2'\n",
    "    out,v = run_simulation(p,verbose=True,online=False)\n",
    "\n",
    "    p['rule'] = 'corr'\n",
    "    out,v2 = run_simulation(p,verbose=True,online=False)\n",
    "\n",
    "    plt.sca(ax)\n",
    "    vplt(v,p,key='sig2',dim=0,cut=1,c=None,err=True,alpha=0.8)\n",
    "    vplt(v2,p,key='sig2',dim=0,cut=1,c=None,err=True,alpha=0.8)\n",
    "    \n",
    "    tau_dd = p['tau_d']\n",
    "    tau_x_wigglee = p['tau_x_wiggle']\n",
    "    plt.title(f'tau_d={tau_dd}, tau_x_wiggle={tau_x_wigglee}')\n",
    "    \n",
    "plt.show(), plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With larger beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['tau_ou'] = 4\n",
    "tau_ds = [0.1,0.5,1]\n",
    "tau_x_wiggles = [0.1,0.5,1]\n",
    "f, axs = plt.subplots(3,3,sharex=True,sharey=True,figsize=[10,10])\n",
    "for ax, (tau_d, tau_x_wiggle) in zip(\n",
    "    axs.reshape(-1), it.product(tau_ds, tau_x_wiggles)):\n",
    "\n",
    "    p['tau_d'] = tau_d*p['tau_ou']\n",
    "    p['tau_x_wiggle'] = tau_x_wiggle*p['tau_ou']\n",
    "    p['beta'] = 0.1\n",
    "    p['dim'] = 1\n",
    "    p['dt'] = 0.001\n",
    "\n",
    "    p['include-spike-response-kernel'] = False\n",
    "    p['include-bias'] = False\n",
    "\n",
    "    p['rule'] = 'exp-rm2'\n",
    "    out,v = run_simulation(p,verbose=True,online=False)\n",
    "\n",
    "    p['rule'] = 'corr'\n",
    "    out,v2 = run_simulation(p,verbose=True,online=False)\n",
    "\n",
    "    plt.sca(ax)\n",
    "    vplt(v,p,key='sig2',dim=0,cut=1,c=None,err=True,alpha=0.8)\n",
    "    vplt(v2,p,key='sig2',dim=0,cut=1,c=None,err=True,alpha=0.8)\n",
    "    \n",
    "    tau_dd = p['tau_d']\n",
    "    tau_x_wigglee = p['tau_x_wiggle']\n",
    "    plt.title(f'tau_d={tau_dd}, tau_x_wiggle={tau_x_wigglee}')\n",
    "    \n",
    "plt.show(), plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Sigma_infty with errorbars as function of beta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10*63000/3600 # hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['tau_ou'] = 4\n",
    "p['tau_d'] = 4\n",
    "p['tau_x_wiggle'] = 6\n",
    "p['beta'] = 0.1\n",
    "p['dim'] = 1\n",
    "p['dt'] = 0.001\n",
    "p['epoch_num'] = 30\n",
    "p['include-spike-response-kernel'] = False\n",
    "p['include-bias'] = False\n",
    "p['compute_sig2'] = True # for plotting?\n",
    "p['online'] = True\n",
    "\n",
    "mp = {'betas': [p['beta']], #np.linspace(0.01,1,21),\n",
    "      'rules':  ('corr','exp','exp-rm2'),\n",
    "      'repeats': range(20),\n",
    "      #'dims': [1,2,3,4,5,7,9,11,13,15,20,25,30,40,50],\n",
    "      'dims': [1,10,50],\n",
    "      'tau': [0.005, 0.025,0.125, 0.625]              \n",
    "      }\n",
    "res = []\n",
    "\n",
    "parameter_list = list(enumerate(it.product(mp['dims'], mp['betas'],\n",
    "                                        mp['rules'], mp['repeats'],\n",
    "                                        mp['tau']\n",
    "                                        )))\n",
    "        \n",
    "length = len(parameter_list)\n",
    "#length = len(list(it.product(mp['betas'], mp['rules'], mp['repeats'])))\n",
    "#res = []\n",
    "\n",
    "#parameter_list = list(enumerate(it.product(mp['betas'],\n",
    " #                                               mp['rules'], mp['repeats'], mp['dims'])))\n",
    "\n",
    "#parameter_list = list(enumerate(it.product(mp['betas'], mp['rules'], mp['repeats'])))\n",
    "\n",
    "for count, (dim, beta, rule, repeat, tau) in parameter_list:    \n",
    "    print(count,'/',length,'rule:',rule,'beta:',beta)\n",
    "    p['rule'] = rule\n",
    "    p['beta'] = beta\n",
    "    p['tau'] = tau\n",
    "    \n",
    "    out,v = run_simulation(p,verbose=True,online=True)\n",
    "    \n",
    "    out = out.mean().to_dict()\n",
    "    out.update({'beta':beta,'rule':rule})       \n",
    "    res.append(out)\n",
    "res = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res(res, metrics = ['MSE','sig2'],ylims=None, xaxis='beta'):\n",
    "    res2 = res[['rule',xaxis] + metrics]\n",
    "    mean = res2.groupby(['rule',xaxis]).mean()\n",
    "    sem = res2.groupby(['rule',xaxis]).sem()\n",
    "\n",
    "    f,axs = plt.subplots(len(metrics),1,figsize=[8,6], tight_layout=True,sharex=True)\n",
    "    for metric,ax in zip(metrics,axs.reshape(-1)):\n",
    "        ax.set_ylabel(metric)\n",
    "\n",
    "        for rule in mp['rules']:\n",
    "            mean.loc[rule,metric].plot(label=rule,ax=ax,marker='o',yerr=sem.loc[rule,metric])\n",
    "            \n",
    "        if ylims is not None:\n",
    "            ax.set_ylim(ylims[metric])\n",
    "            \n",
    "        ax.legend(ncol=len(mp['rules']))\n",
    "        #ax.set_xscale('log')\n",
    "        ax.set_title(metric)\n",
    "        #ax.set_yscale('log')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ./../c_20-Mar-2021-low_high_tau_x_rho3_longlong/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "#file_path = Path('./../c_28-Feb-2021-beta_lin/pkl_data/')\n",
    "#file_path = Path('./../c_07-Mar-2021-beta_lin_dim2/pkl_data/')\n",
    "#file_path = Path('./../c_14-Mar-2021-low_high_tau_x_rho3/pkl_data/')\n",
    "#file_path = Path('./../c_15-Mar-2021-low_high_tau_x_rho3_long/pkl_data/')\n",
    "#file_path = Path('./../c_20-Mar-2021-low_high_tau_x_rho3_longlong/pkl_data/')\n",
    "#file_path = Path('./../c_20-Mar-2021-low_high_tau_x_rho3_long_gamma/pkl_data/') -> instable\n",
    "#file_path = Path('./../c_21-Mar-2021-low_high_tau_x_rho3_long_beta_smaller_g0/pkl_data/') # -> beta 0.1, g0: not unstable, but worse MSE\n",
    "file_path = Path('./../c_21-Mar-2021-low_high_tau_x_rho3_long_beta_smaller/pkl_data/') # -> beta 0.1, gamma: unstable but a bit later\n",
    "#file_path = Path('./../c_21-Mar-2021-low_high_tau_x_rho3_longlong2/pkl_data/') # -> tau_ou=300s, g0: unstable\n",
    "\n",
    "# Qs:\n",
    "# g0 vs gamma\n",
    "# long vs short\n",
    "\n",
    "import pickle\n",
    "def load_obj(name, path='./'):\n",
    "    #    print('load obj:',os.getcwd())\n",
    "    with open(path + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = pd.concat([load_obj(str(path)[:-4]) for path in file_path.glob('**/*.pkl')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3[(res3.dim==1) & (res3.rule == 'exp-rm2')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "low high analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res3.copy()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = res.groupby(['rule','tau','dim']).mean().reset_index()\n",
    "m2 = m[m.tau != .625].sort_values('count').set_index('tau_rho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axs = plt.subplots(1,3,figsize=[10,6],tight_layout=True,sharey=True)\n",
    "for dim,ax in zip(m2.dim.unique(),axs):\n",
    "    m3 = m2.loc[m2.dim==dim,['rule','MSE']]\n",
    "    #ax = None\n",
    "    for rule in m3.rule.unique():\n",
    "        ax = m3[m3.rule==rule].plot(y='MSE',label=rule,ax=ax,marker='o')\n",
    "    ax.axvline(x=1, ls='--', c='gray')\n",
    "    ax.set_title('dim: ' + str(dim))    \n",
    "    ax.set_ylim([0.0,1.5])\n",
    "    if axs[0] is ax:\n",
    "        ax.set_ylabel('MSE')\n",
    "    #ax.set_xticks(m2.index.drop_duplicates())\n",
    "    #ax.set_xscale('log')\n",
    "plt.suptitle('MSE vs dimensionless input strength (firing rate time membrane constant)',y=1.05)\n",
    "plt.savefig('MSE_vs_input_tauOU400_gamma.png',dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim beta analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_res(res3, metrics=['MSE','L'], ylims={'MSE':(0.6,1.1), 'sig2':(0,1.1) }, xaxis='dim')\n",
    "metrics = ['MSE','L']\n",
    "#def plot_res(res, metrics = ['MSE','sig2'],ylims=None, xaxis='beta'):\n",
    "xaxis='dim'\n",
    "res2 = res[['rule',xaxis] + metrics]\n",
    "mean = res2.groupby(['rule',xaxis]).mean()\n",
    "sem = res2.groupby(['rule',xaxis]).sem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylims={'MSE':(0.6,1.5), 'L':(-0.1,0.1) }\n",
    "f,axs = plt.subplots(len(metrics),1,figsize=[8,6], tight_layout=True,sharex=True)\n",
    "for metric,ax in zip(metrics,axs.reshape(-1)):\n",
    "    ax.set_ylabel(metric)\n",
    "\n",
    "    for rule in ['exp', 'corr','exp-rm2']:\n",
    "        mean.loc[rule,metric].plot(label=rule,ax=ax,marker='o',yerr=sem.loc[rule,metric])\n",
    "\n",
    "    if ylims is not None:\n",
    "        ax.set_ylim(ylims[metric])\n",
    "\n",
    "    ax.legend(ncol=len(mp['rules']))\n",
    "    ax.set_title(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights:\n",
    "- exp-rm2 has no loglike because of gamma = g0\n",
    "- without beta scaling, high dim values wont work\n",
    "- all corr-sims were killed (probably because they contained a dim=100 case)\n",
    "\n",
    "Mitigation:\n",
    "- focus on dim only\n",
    "- scale beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i_max = 100\n",
    "i = 0\n",
    "mp = {'betas': [p['beta']], #np.linspace(0.01,1,21),\n",
    "      'rules':  ('corr','exp','exp-rm2'),\n",
    "      'repeats': range(5),\n",
    "      'dims': [1, 5, 10, 50, 100]}\n",
    "res = []\n",
    "\n",
    "parameter_list = list(enumerate(it.product(mp['betas'], mp['rules'], mp['repeats'], mp['dims'])))\n",
    "length = len(parameter_list)\n",
    "\n",
    "def assign_parameters_to_maximally_imax_nodes(i_max, i, parameter_list):\n",
    "    num_pars = len(parameter_list)\n",
    "    ii_to_run = np.where(np.arange(num_pars)[[int(ii/(num_pars/i_max)) for ii in range(num_pars)]] == i)[0]\n",
    "    parameter_list_to_run = [parameter_list[ii] for ii in ii_to_run]\n",
    "    return parameter_list_to_run\n",
    "\n",
    "\n",
    "if i != -1:\n",
    "    # maximally i_max sims\n",
    "    if len(parameter_list) < i_max + 1:\n",
    "        parameter_list = [parameter_list[i]]\n",
    "    else:\n",
    "        parameter_list = assign_parameters_to_maximally_imax_nodes(\n",
    "                        i_max=i_max, i=i, parameter_list=parameter_list)\n",
    "parameter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res)\n",
    "plot_res(res3,['MSE','sig2','L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res.rule=='corr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Older stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = p['sig2_ou']*p['beta']**2*p['g0dt']/p['dt']*p['tau_ou']/2\n",
    "out.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axs = plt.subplots(p['dim'],1,figsize=[12,10])\n",
    "for dim,ax in zip(range(p['dim']),axs.reshape(-1)):\n",
    "    plt.sca(ax)\n",
    "    vplt(v,p,key='filter',dim=dim,cut=1,c=None,err=True,alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_list = list(enumerate(it.product(mp['betas'], mp['rules'], mp['repeats'])))\n",
    "def assign_parameters_to_maximally_imax_nodes(i_max, i, parameter_list):\n",
    "    num_pars = len(parameter_list)\n",
    "    ii_to_run = np.where(np.arange(num_pars)[[int(ii/(num_pars/i_max)) for ii in range(num_pars)]] == i)[0]\n",
    "    parameter_list_to_run = [parameter_list[ii] for ii in ii_to_run]\n",
    "    return parameter_list_to_run\n",
    "i_max = 100\n",
    "i = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_parameters_to_maximally_imax_nodes(i_max,i,parameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['tau_ou'] = 5*20\n",
    "p['tau_z'] = 5*20\n",
    "p['beta'] = 0.1\n",
    "p['dim'] = 1\n",
    "p['dt'] = 0.001\n",
    "p['epoch_num'] = 50 # 2 * 2 * 5 = 20\n",
    "p['include-spike-response-kernel'] = False\n",
    "p['include-bias'] = False\n",
    "\n",
    "mp = {'betas': expspace(0.001,0.3,5*2),\n",
    "      'rules':  ('corr','exp','exp-rm2') , # ('exp','corr','exp-oja','exp-rm'), \n",
    "      'repeats': range(20)}\n",
    "length = len(list(it.product(mp['betas'], mp['rules'], mp['repeats'])))\n",
    "res = []\n",
    "\n",
    "\n",
    "parameter_list = list(enumerate(it.product(mp['betas'], mp['rules'], mp['repeats'])))\n",
    "\n",
    "for count, (beta, rule, repeat) in parameter_list:    \n",
    "    print(count,'/',length,'rule:',rule,'beta:',beta)\n",
    "    p['rule'] = rule\n",
    "    p['beta'] = beta\n",
    "    out,v = run_simulation(p,verbose=True,online=True)\n",
    "    out = out.mean().to_dict()        \n",
    "    \n",
    "    # what about diag vs matrix??? corr vs exp-rm2\n",
    "    mean = np.mean(v['sig2'][k0:k])\n",
    "    std = np.std(v['sig2'][k0:k])\n",
    "            \n",
    "    print(rule,mean,std)\n",
    "    \n",
    "    out.update({'beta':beta,'rule':rule})                \n",
    "    out.update({'Sigma_mean': mean})\n",
    "    out.update({'Sigma_std': std})\n",
    "    out.update({'alpha_bar': A3})\n",
    "    \n",
    "    \n",
    "    res.append(out)    \n",
    "res = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from util.util import load_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../c_08-Feb-2021-beta100/pkl_data/'\n",
    "dfs = []\n",
    "for file in [file for file in os.listdir(path) if 'pkl' in file[-4:]]:\n",
    "    dfs.append(load_obj(path + file[:-4]))\n",
    "dfs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_parameters_to_maximally_imax_nodes(i_max, i, parameter_list):\n",
    "    num_pars = parameter_list\n",
    "    ii_to_run = np.where(np.arange(num_pars)[[int(ii/(num_pars/i_max)) for ii in range(num_pars)]] == i)[0]\n",
    "    parameter_list_to_run = [parameter_list[ii] for ii in ii_to_run]\n",
    "    return parameter_list_to_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dfs.copy()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### eval sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res.drop(list(res.columns)[1:6],axis=1)\n",
    "mean = res2.groupby(['rule','beta']).mean()\n",
    "sem = res2.groupby(['rule','beta']).sem()\n",
    "\n",
    "f,axs = plt.subplots(4,1,figsize=[12,10])\n",
    "for metric,ax in zip(('MSE','Sigma_mean','Sigma_std','alpha_bar'),axs.reshape(-1)):\n",
    "    ax.set_ylabel(metric)\n",
    "    \n",
    "    # fix\n",
    "#    if 'L' in metric:\n",
    " #       ax.set_ylim([-0.00000001,0.00000001])\n",
    "     #   mean[metric] += 1\n",
    "                    \n",
    "    for rule in mp['rules']:\n",
    "        #if ((rule != 'corr') and (metric != 'alpha_bar')):     \n",
    "        mean.loc[rule,metric].plot(label=rule,ax=ax,marker='o',yerr=sem.loc[rule,metric])\n",
    "    ax.legend(ncol=len(mp['rules']))\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res.sort_values('count').drop(list(res.columns)[3:6],axis=1)\n",
    "\n",
    "res2 = res2[res2.beta < 0.1]\n",
    "\n",
    "mean = res2.groupby(['rule','beta']).mean()\n",
    "sem = res2.groupby(['rule','beta']).sem()\n",
    "\n",
    "f,axs = plt.subplots(1,3,figsize=[12,6], tight_layout=True)\n",
    "for metric,ax in zip(('MSE','L','L_pt'),axs.reshape(-1)):\n",
    "    ax.set_ylabel(metric)\n",
    "    \n",
    "    # fix\n",
    "    if 'L' in metric:\n",
    "        #ax.set_ylim([-0.00000001,0.00000001])\n",
    "        unit = 10**6\n",
    "        mean[metric] *= unit\n",
    "        sem[metric] *= unit\n",
    "    #for rule in ['corr','exp']:\n",
    "    for rule in mp['rules']:\n",
    "        mean.loc[rule,metric].plot(label=rule,ax=ax,marker='o',yerr=sem.loc[rule,metric])\n",
    "    ax.legend() #ncol=len(mp['rules']))\n",
    "    ax.set_xscale('log')\n",
    "    #ax.set_yscale('log')\n",
    "f.suptitle(r'Parameters: $T_{\\max}=50 \\tau_{ou}, \\tau_{ou} = \\tau_{z} = 100s, d=1, n_{sim} = 20$', y=1.05)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did I learn from this?\n",
    "1. I can run on cluster again. Good.\n",
    "2. Probably multiple tau_z = 100s are needed.\n",
    "3. Probably more averaging is needed.\n",
    "4. Very small beta is not meaningful, zoom into the range.\n",
    "5. be less verbose in output\n",
    "6. g0 vs gamma_approx\n",
    "7. check sigma_t vs sigma_approx_t -> quantify the difference between the true and false?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STDP / Heterosynaptic plasticity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = {'num_delta_T':21,\n",
    "      'delta_T_max':0.1,\n",
    "      'delta_T_min':-0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare two rules for single time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rule = 'exp-rm'\n",
    "p['rule'] = test_rule\n",
    "p['delta_T'] = 0.1\n",
    "p['dim'] = 1\n",
    "v, states = run_timeseries(p,hetero=False)\n",
    "\n",
    "p['rule'] = 'corr'\n",
    "v2, states = run_timeseries(p,hetero=False)\n",
    "\n",
    "#p['rule'] = 'corr'\n",
    "#v2, states = run_timeseries(p,hetero=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,tight_layout=True, sharex=True)\n",
    "plt.sca(axs[0,0])\n",
    "vplt(v,p,'mu',0) #, plt.xlim([0.45,.55])\n",
    "plt.title('deltaT={0}, dim={1}, beta={2}'.format(p['delta_T'],p['dim'],p['beta']))\n",
    "plt.sca(axs[0,1])\n",
    "\n",
    "vplt(v2,p,'mu',0,c='red') #, plt.xlim([0.45,.55])\n",
    "plt.title('deltaT={0}, dim={1}, beta={2}'.format(p['delta_T'],p['dim'],p['beta']))\n",
    "\n",
    "plt.sca(axs[1,0])\n",
    "vplt(v,p,'sig2',0) #, plt.xlim([0.45,.55])\n",
    "#plt.title('sig2(t) and z(t)')\n",
    "plt.ylabel('z(t)')\n",
    "plt.sca(axs[1,1])\n",
    "vplt(v2,p,'sig2',0,c='red') #, plt.xlim([0.45,.55])\n",
    "#plt.title('sig2(t) and z(t)')\n",
    "#plt.gca().legend(['exp-z','corr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare STDP protocol for two rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['dim'] = 1\n",
    "p['rule'] = test_rule\n",
    "out = run_STDP(mp,p)\n",
    "p['rule'] = 'corr'\n",
    "out2 = run_STDP(mp,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0\n",
    "def plt_stdp(out,d=0,c='k'):\n",
    "    xplt, dmu = np.array([(item['delta_T'], item['mu_f'][d] - item['mu_0'][d]) for item in out]).T\n",
    "    plt.plot(xplt,dmu,c=c)\n",
    "    plt.title('beta={0}, rule={1}'.format(p['beta'],p['rule']))\n",
    "\n",
    "fig, axs = plt.subplots(1,2,tight_layout=True)\n",
    "plt.sca(axs[0])\n",
    "p['rule'] = test_rule\n",
    "plt_stdp(out)\n",
    "p['rule'] = 'corr'\n",
    "plt.sca(axs[1])\n",
    "plt_stdp(out2,c='red')\n",
    "#plt.gca().legend(['exp-z','corr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['rule'] = 'corr' # SF\n",
    "p['dim'] = 2\n",
    "v, states = run_timeseries(p,hetero=True)\n",
    "out = run_STDP(mp,p,hetero=True)\n",
    "\n",
    "p['rule'] = test_rule\n",
    "v2, states = run_timeseries(p,hetero=True)\n",
    "out2 = run_STDP(mp,p,hetero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = p['beta']**2*(p['g0dt']/p['dt'])*p['tau_ou'] # OK \n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,tight_layout=True)\n",
    "for i, out_i, rule in zip([0,1],[out,out2],['corr',test_rule] ):\n",
    "    plt.sca(axs[i])\n",
    "    d = 0\n",
    "    xplt, dmu = np.array([(item['delta_T'], item['mu_f'][d] - item['mu_0'][d]) for item in out_i]).T\n",
    "    d = 1\n",
    "    xplt, dmu2 = np.array([(item['delta_T'], item['mu_f'][d] - item['mu_0'][d]) for item in out_i]).T\n",
    "    plt.plot(xplt,dmu,c='k',lw=1,label='Syn 1')\n",
    "    plt.plot(xplt,dmu2,c='red',lw=1,label='Syn 2')\n",
    "    plt.gca().legend()\n",
    "    plt.title('Hetero {1} b={0}'.format(p['beta'],rule))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
